# 四线流水线调试说明

## 🔍 问题分析

### 问题1：四条线没有真正重叠工作（已修复 v2.4）

**表面现象**：
从日志看，Line1处理完所有17张图片后，Line2才开始翻译。

**根本原因**：
asyncio事件循环调度问题！Line1的CPU密集任务（检测、OCR）虽然使用了`await`，但内部是同步代码，长时间占用事件循环，导致Line2/3/4的任务虽然创建但无法执行。

**技术细节**：
- Line1的17个任务在08:54:57创建并立即开始执行
- Line1的检测、OCR是CPU密集型同步代码，占用事件循环
- Line2/3/4的任务虽然创建，但`await ocr_queue.get()`无法执行
- 只有当Line1完成后释放事件循环，Line2才能运行

**修复方案 (v2.4)**：
在Line1的每个主要步骤后添加`await asyncio.sleep(0)`，强制让出事件循环控制权：
- 检测后 → `await asyncio.sleep(0)`
- OCR后 → `await asyncio.sleep(0)`
- 文本合并后 → `await asyncio.sleep(0)`
- 数据入队后 → `await asyncio.sleep(0)`

这样Line2/3/4可以在Line1处理过程中获得执行机会，实现真正的并行。

### 问题2：漏翻图片（16和17）

**表面现象**：
Line3只处理了15张图片，缺少16和17。

**真实情况**：
从日志看：
```
08:48:24 - Line2: Line1已完成且队列为空，退出
--- Stop request received.  ← 用户手动停止了任务！
```

**根本原因**：
用户在Line2处理完部分图片后手动停止了任务，导致16和17没有被处理完成。

### 问题3：批量翻译（打包）功能验证

**问题**：打包功能是否真正生效？

**答案**：✅ **是的，打包功能完全正常！**

**证据**：
从日志可以看到Line2每次处理3个项目（批量大小=3）：
```
08:55:50 - Line2: 开始批量翻译 3 个项目  ← 第一批
08:55:55 - Line2: 完成批量翻译 3 个项目
08:55:55 - Line2: 开始批量翻译 3 个项目  ← 第二批
08:56:12 - Line2: 完成批量翻译 3 个项目
```

**并发工作**：
有3个Line2 worker并发工作（配置：`pipeline_line2_concurrency=3`）：
```
08:55:50 - Line2: 翻译工作线程已启动  # worker 1
08:55:50 - Line2: 开始批量翻译 3 个项目
08:55:50 - Line2: 翻译工作线程已启动  # worker 2
08:55:50 - Line2: 开始批量翻译 3 个项目
08:55:50 - Line2: 翻译工作线程已启动  # worker 3
08:55:50 - Line2: 开始批量翻译 3 个项目
```

**结论**：
- 批量大小（3）正确生效 ✅
- 3个worker并发工作 ✅
- 批量翻译API调用正常 ✅

## ✅ 已实施的修复

### 0. asyncio事件循环调度优化 (v2.4)

**问题**：Line1占用事件循环，导致Line2/3/4无法执行。

**修复**：在Line1的每个CPU密集步骤后添加yield点：
```python
# 在检测、OCR、文本合并、数据入队后
await asyncio.sleep(0)  # 强制让出控制权
```

**效果**：Line2/3/4可以在Line1处理过程中获得执行机会，实现真正的并行。

### 1. 增强日志系统

#### Line1并发提示
```python
logger.info(f"Line1: [并发{self.pipeline_line1_concurrency}] 开始处理图片 {index+1}/{total_images}")
```

#### 队列监控
```python
logger.debug(f"Line1: 图片{index+1}已放入ocr_queue，当前队列大小: {ocr_queue.qsize()}")
logger.debug(f"Line2: 从队列获取图片{image_idx+1}，当前批次大小: {len(batch_buffer)}")
```

#### 超时详情
```python
logger.debug(f"Line2: 超时{consecutive_timeouts}次，队列大小: {ocr_queue.qsize()}, Line1完成: {all(task.done() for task in line1_tasks)}")
```

### 2. 改进退出逻辑

**修复前**：
```python
if consecutive_timeouts >= max_consecutive_timeouts:
    if all(task.done() for task in line1_tasks):
        break
```

**修复后**：
```python
if consecutive_timeouts >= max_consecutive_timeouts:
    if all(task.done() for task in line1_tasks) and ocr_queue.empty():
        logger.info(f"Line2: Line1已完成且队列为空（连续{consecutive_timeouts}次超时），退出")
        break
    else:
        # 检查队列是否真的为空
        if not ocr_queue.empty():
            logger.debug(f"Line2: 队列不为空（{ocr_queue.qsize()}项），重置超时计数")
            consecutive_timeouts = 0
```

## 🎯 如何验证真正的并行

### 1. 启用详细日志

在UI中启用"详细日志"选项，或在命令行添加`--verbose`参数。

### 2. 观察关键日志

**正确的并行执行应该看到**：

```
08:46:14 - Line1: [并发6] 开始处理图片 1/17
08:46:14 - Line1: [并发6] 开始处理图片 2/17  ← 同时启动
08:46:14 - Line1: [并发6] 开始处理图片 3/17  ← 同时启动
08:46:14 - Line1: [并发6] 开始处理图片 4/17  ← 同时启动
08:46:14 - Line1: [并发6] 开始处理图片 5/17  ← 同时启动
08:46:14 - Line1: [并发6] 开始处理图片 6/17  ← 同时启动

08:46:29 - Line1: 完成处理图片 1/17
08:46:29 - Line1: 图片1已放入ocr_queue，当前队列大小: 1
08:46:29 - Line1: [并发6] 开始处理图片 7/17  ← 立即处理下一张

08:46:30 - Line1: 完成处理图片 2/17
08:46:30 - Line2: 从队列获取图片1，当前批次大小: 1

08:46:32 - Line1: 完成处理图片 3/17
08:46:32 - Line2: 从队列获取图片2，当前批次大小: 2

08:46:33 - Line1: 完成处理图片 4/17
08:46:33 - Line2: 从队列获取图片3，当前批次大小: 3
08:46:33 - Line2: 开始批量翻译 3 个项目  ← 达到批量大小，开始翻译

08:46:35 - Line1: 完成处理图片 5/17  ← Line1继续处理
08:46:40 - Line2: 完成批量翻译 3 个项目
08:46:40 - Line3: 开始修复处理图片 1/17  ← Line3开始工作
```

### 3. 性能指标

**真正的并行应该满足**：
- Line1的6个任务几乎同时启动（时间戳相同或相差<1秒）
- Line2在Line1完成第3张图片后立即开始翻译
- Line3在Line2完成第一批翻译后立即开始修复
- Line4在Line3完成第一张修复后立即开始渲染

## 📊 优化建议

### 1. 调整批量大小

如果想让Line2更早开始：
```python
pipeline_translation_batch_size: 2  # 从3改为2
```

### 2. 调整并发数

根据GPU内存和CPU核心数：
```python
pipeline_line1_concurrency: 4  # 减少到4，避免GPU内存不足
pipeline_line3_concurrency: 2  # 增加到2，加快修复速度
```

### 3. 监控队列大小

如果经常看到队列积压（qsize > 10），说明某个环节是瓶颈：
- `ocr_queue`积压 → Line2太慢，增加`pipeline_line2_concurrency`
- `translate_queue`积压 → Line3太慢，增加`pipeline_line3_concurrency`
- `inpaint_queue`积压 → Line4太慢，增加`pipeline_line4_concurrency`

## ⚠️ 重要提示

### 不要手动停止任务

如果必须停止，请等待当前批次完成，否则会导致：
- 部分图片未处理
- 队列中的数据丢失
- 文件保存不完整

### 检查完整性

翻译完成后，检查输出目录：
```bash
# 检查输出文件数量
ls 输出目录 | wc -l

# 应该等于输入文件数量
ls 输入目录 | wc -l
```

## 🔧 故障排查

### 如果发现漏翻

1. 检查日志中是否有"Stop request received"
2. 检查是否有错误日志
3. 重新运行翻译，只处理缺失的文件

### 如果性能没有提升

1. 启用详细日志，检查并发是否真正工作
2. 检查GPU使用率（应该保持在70%以上）
3. 检查队列大小，找出瓶颈环节
4. 调整各线程的并发数

---

## 📝 版本历史

### v2.5 (2025-11-15)
**重大修复：上下文翻译功能 + 图片未翻译诊断**

**问题1**：上下文翻译功能没有生效
- **根本原因**：`_process_translation_batch`调用`_batch_translate_texts`时没有传递`page_index`参数
- **修复方案**：
  - 添加批次计数器`page_counter = {'count': 0}`
  - 修改`_process_translation_batch`签名，添加`page_counter`参数
  - **每个批次作为独立上下文单位**，按批次递增
  - `page_index`代表"批次序号"（第0批、第1批、第2批...）
  - 递增量 = 1（每批次递增1）
- **预期效果**：
  - 批次1（batch_index=0）：无上下文（正常）
  - 批次2（batch_index=1）：显示"Context-aware translation enabled with 3 pages of history"
  - 批次3（batch_index=2）：持续使用上下文

**问题2**：部分图片（如001、002、003、016、017）没有被翻译
- **诊断增强**：
  - Line1显示文本合并前后的数量对比
  - Line1显示每个text_region的文本内容（debug级别）
  - Line2显示每个图片的text_regions数量和文本内容（debug级别）
  - Line2统计批次总共提取到多少文本
  - Line2警告：如果批次中没有文本需要翻译
- **可能原因**：
  - 文本被判定为"无价值"（如"..."、"……"）
  - 文本长度小于最小长度要求
  - 源语言和目标语言相同
- **详见**：`图片未翻译问题诊断.md`和`v2.5-上下文翻译修复说明.md`

### v2.4 (2025-11-15)
**重大修复：asyncio事件循环调度问题**

**问题**：Line1和Line2/3/4不是真正同时工作，Line1完成后Line2才开始。

**根本原因**：Line1的CPU密集任务（检测、OCR）占用事件循环，导致Line2/3/4无法执行。

**修复方案**：
在Line1的每个主要步骤后添加`await asyncio.sleep(0)`：
```python
# 检测后
await asyncio.sleep(0)

# OCR后
await asyncio.sleep(0)

# 文本合并后
await asyncio.sleep(0)

# 数据入队后
await asyncio.sleep(0)
```

**预期效果**：
- Line2在Line1完成第1-3张图片后就开始翻译
- Line3在Line2完成第一批翻译后立即开始修复
- Line4在Line3完成第一张修复后立即开始渲染
- 真正的四线重叠并行执行

### v2.3 (2025-11-15)
- 增强日志系统，添加并发提示和队列监控
- 改进Line2退出逻辑，确保队列真正为空
- 移除无效的`_update_translation_map`调用

---

**当前版本**: v2.5  
**更新日期**: 2025-11-15  
**状态**: 已修复上下文翻译功能，增强图片未翻译诊断

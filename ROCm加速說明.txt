
Manga Translator UI - ROCm 7 加速版本
====================================
�!manga-translator-ui 已配置為使用 ROCm 7 GPU 加速。

========================================
已配置的加速環境
========================================

✓ 獨立 Conda 環境配置
✓ PyTorch 2.9.0 + ROCm 7.10.0
✓ AMD Radeon RX 9000 系列 (gfx1201) GPU 支持
✓ 所有翻譯器依賴已安裝

========================================
啟動方式
========================================

方式一：使用 ROCm 啟動腳本（推薦）
   雙擊：D:\漫画\1\manga-translator-ui\start-rocm.bat

方式二：手動啟動
   1. 打開 CMD
   2. cd D:\漫画\1\manga-translator-ui
   3. conda activate manga
   4. python -m desktop_qt_ui.main

========================================
GPU 加速優勢
========================================

使用 ROCm 7 GPU 加速後：

1. 文本檢測速度提升：約 5-10 倍
2. OCR 識別速度提升：約 3-5 倍
3. 圖像修復速度提升：約 10-20 倍
4. 整體翻譯速度：提升約 10 倍

示例：
- CPU 模式：1 張漫畫頁約需 30-60 秒
- GPU 模式：1 張漫畫頁約需 3-6 秒

========================================
設置建議
========================================

在 Manga Translator UI 界面中：

1. 基礎設置：
   ✓ 勾選「使用 GPU」
   ✓ 不勾選「使用受限 GPU」（除非顯存不足）

2. 檢測器設置：
   - 檢測大小：2048（默認，推薦）
   - 如果顯存不足，可降至 1536 或 1024

3. 修復器設置：
   - 修復模型：lama_large（推薦，效果最好）
   - 修復精度：fp16 或 bf16（速度快）

4. OCR 設置：
   - OCR 模型：48px 或 48px_ctc（推薦）

========================================
性能監控
========================================

查看 GPU 使用情況：
1. 在翻譯過程中，查看控制台日志
2. 應該看到類似信息：
   - "Using device: cuda"
   - "GPU memory: XXXX MB"

如果顯示 "Using device: cpu"，說明未啟用 GPU。

========================================
常見問題
========================================

Q1: 提示「CUDA not available」？
A: 確保使用 start-rocm.bat 啟動
   環境變量已正確設置

Q2: 翻譯速度沒有明顯提升？
A: 檢查「基礎設置」中是否勾選「使用 GPU」
   首次運行需要加載模型，之後會更快

Q3: 顯存不足錯誤？
A: 勾選「使用受限 GPU」
   或降低檢測大小和修復大小

Q4: 某些模型無法使用 GPU？
A: 某些翻譯器（如離線翻譯器）可能不支持 GPU
   但文本檢測、OCR、圖像修復都會使用 GPU

========================================
環境管理
========================================

Manga Translator UI 使用獨立的 Conda 環境 (manga)：

優點：
- 環境隔離，避免依賴衝突
- 易於管理和維護
- 可以獨立更新或卸載

創建環境（首次安裝）：

1. 創建新環境：
   conda create -n manga python=3.13 -y

2. 安裝 PyTorch + ROCm 7：
   conda activate manga
   python -m pip install --index-url https://d2awnip2yjpvqn.cloudfront.net/v2/gfx120X-all/ torch torchvision torchaudio

3. 安裝依賴：
   cd D:\漫画\1\manga-translator-ui
   pip install -r requirements_rocm.txt

4. 使用啟動腳本：
   雙擊 start-rocm.bat（已自動配置環境）

========================================
技術信息
========================================

項目目錄：D:\漫画\1\manga-translator-ui
Conda 環境：manga (獨立環境)
PyTorch 版本：2.9.0+rocm7.10.0a20251031
ROCm 版本：7.10.0
Python 版本：3.13.9
GPU 架構：gfx1201

環境變量：
- HSA_OVERRIDE_GFX_VERSION=12.0.1
- PYTORCH_ROCM_ARCH=gfx1201

========================================
相關鏈接
========================================

- 項目 GitHub：https://github.com/hgmzhn/manga-translator-ui
- ROCm 文檔：https://rocm.docs.amd.com/

========================================

現在您可以使用 GPU 加速來翻譯漫畫了！ 🚀📖
============================================




# Windows + ROCm 7 + PyTorch + Manga Translator UI 部署指南（gfx1201 顯卡專用）

> 適用於 AMD Radeon RX 9000 系列（gfx1201 架構）
> 無需 WSL，Windows 原生環境部署
> 專為漫畫翻譯工具優化的 ROCm 加速配置

---

## 📋 系統要求

- **操作系統**：Windows 10/11 (64位)
- **顯卡**：AMD Radeon RX 9000 系列（gfx1201 架構）
- **內存**：建議 ≥16GB
- **硬盤空間**：≥50GB 可用空間

---

## 🚀 部署步驟

### 步驟 1：安裝 Python 3.13

1. 下載 Python 3.13：
   ```
   https://www.python.org/ftp/python/3.13.0/python-3.13.0-amd64.exe
   ```

2. 安裝時 **必須勾選**：
   - ✅ Add Python 3.13 to PATH
   - ✅ Install for all users（可選）

3. 驗證安裝：
   ```powershell
   python --version
   # 應顯示：Python 3.13.x
   ```

---

### 步驟 2：安裝 Anaconda/Miniconda

1. 下載 Miniconda（推薦，體積小）：
   ```
   https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe
   ```

2. 安裝時選擇：
   - ✅ Add Anaconda to PATH（可選，方便使用）
   - ✅ Register Anaconda as system Python

3. 驗證安裝：
   ```powershell
   conda --version
   ```

---

### 步驟 3：安裝 Visual Studio 2022

1. 下載 Visual Studio Community 2022：
   ```
   https://visualstudio.microsoft.com/zh-hans/downloads/
   ```

2. 安裝時選擇工作負載：
   - ✅ **使用 C++ 的桌面開發**

3. 確保以下組件已安裝：
   - MSVC v143 - VS 2022 C++ x64/x86 生成工具
   - Windows 11 SDK
   - C++ CMake 工具
   - C++ ATL

---

### 步驟 4：安裝 Git

1. 下載 Git for Windows：
   ```
   https://git-scm.com/download/win
   ```

2. 安裝時使用默認選項即可

3. 驗證安裝：
   ```powershell
   git --version
   ```

---

### 步驟 5：克隆 Manga Translator UI 倉庫

1. 選擇安裝目錄（例如：`D:\manga-translator-ui`）

2. 打開 PowerShell 或 CMD，執行：
   ```powershell
   # 切換到目標目錄
   cd D:\
   
   # 克隆 Manga Translator UI
   git clone https://github.com/hgmzhn/manga-translator-ui.git
   
   # 進入目錄
   cd manga-translator-ui
   ```

---

### 步驟 6：配置 ROCm 7 + PyTorch 環境（核心步驟）

#### 6.1 創建虛擬環境

```powershell
# 創建名為 manga 的 Python 3.13 環境
conda create -n manga python=3.13

# 激活環境
conda activate manga
```

#### 6.2 安裝 PyTorch + ROCm 7（gfx1201 專用）

```powershell
# 重要：使用 gfx120X-all 索引（gfx1201 屬於此系列）
python -m pip install --index-url https://d2awnip2yjpvqn.cloudfront.net/v2/gfx120X-all/ torch torchvision torchaudio
```

⏱️ **安裝時間**：約 5-15 分鐘（取決於網速）

#### 6.3 驗證安裝

```powershell
# 驗證 ROCm SDK
rocm-sdk test

# 應輸出：OK

# 驗證 PyTorch
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

# 應顯示 PyTorch 版本和 True
```

---

### 步驟 7：安裝 Manga Translator UI 依賴

```powershell
# 確保在 Manga Translator UI 目錄下
cd D:\manga-translator-ui

# 確保 manga 環境已激活
conda activate manga

# 安裝 ROCm 依賴
pip install -r requirements_rocm.txt
```

---

### 步驟 8：首次啟動測試

```powershell
# 使用 ROCm 啟動腳本（推薦）
start-rocm.bat

# 或手動啟動
python -m desktop_qt_ui.main
```

如果成功，會打開 Qt 界面窗口。

---

## 🎯 創建一鍵啟動腳本

Manga Translator UI 已包含 ROCm 啟動腳本：`start-rocm.bat`

如果需要自定義路徑，請編輯 `start-rocm.bat` 並修改以下變量：

```batch
set "CONDA_ROOT=C:\Users\longxin\miniconda3"      REM 修改為你的 Conda 路徑
set "PROJECT_DIR=D:\manga-translator-ui"          REM 修改為你的項目路徑
set "CONDA_ENV=manga"                             REM Conda 環境名稱
```

雙擊 `start-rocm.bat` 即可一鍵啟動！

---

## 📦 下載翻譯模型（可選）

Manga Translator UI 首次運行時會自動下載所需的模型文件。

### 模型存放位置
```
D:\manga-translator-ui\models\
```

### 手動下載（可選）

如果自動下載失敗，可以從以下位置手動下載：

1. **文本檢測模型**：自動從 GitHub Releases 下載
2. **OCR 模型**：自動從 Hugging Face 下載
3. **修復模型**：自動從官方源下載

所有模型會在使用時自動下載，無需手動操作。

---

## ⚙️ 優化設置

### 啟用 GPU 加速

Manga Translator UI 會自動檢測 ROCm，無需額外配置。

### 查看 GPU 使用情況

在 Manga Translator UI 啟動後，可在界面中：
1. 打開「基礎設置」
2. 勾選「使用 GPU」
3. 在翻譯過程中查看控制台輸出，應顯示：
```
Using device: cuda
GPU memory: XXXX MB
```

### 如果遇到顯存不足

在 Manga Translator UI 界面中：
1. 勾選「使用受限 GPU」
2. 降低「檢測大小」（2048 → 1536 或 1024）
3. 降低「修復大小」參數

---

## 🐛 常見問題排查

### 問題 1：`rocm-sdk test` 失敗

**解決方案**：
```powershell
# 檢查 PyTorch 是否正確安裝
python -c "import torch; print(torch.__version__)"

# 如果失敗，重新安裝
pip uninstall torch torchvision torchaudio
python -m pip install --index-url https://d2awnip2yjpvqn.cloudfront.net/v2/gfx120X-all/ torch torchvision torchaudio
```

### 問題 2：DLL 初始化失敗

**解決方案**：
1. 確保顯卡驅動是最新版本
2. 以管理員身份運行所有安裝和啟動命令
3. 重啟電腦後再試

### 問題 3：Manga Translator UI 無法啟動

**解決方案**：
1. 確認 Conda 環境 `manga` 已創建並激活
2. 確認所有依賴已安裝：`pip install -r requirements_rocm.txt`
3. 檢查 PyTorch ROCm 支持：`python -c "import torch; print(torch.cuda.is_available())"`

### 問題 4：翻譯速度很慢或未使用 GPU

**解決方案**：
1. 確認 GPU 已被識別（查看控制台是否顯示 "Using device: cuda"）
2. 在「基礎設置」中勾選「使用 GPU」
3. 檢查環境變量是否設置：`echo %HSA_OVERRIDE_GFX_VERSION%`

---

## 📊 性能參考

**gfx1201 (RX 9000 系列) 預期性能**：
- 單頁翻譯（ROCm 加速）：約 3-6 秒/頁
- 單頁翻譯（CPU 模式）：約 30-60 秒/頁
- 性能提升：整體約 **10 倍**加速
  - 文本檢測：5-10倍提升
  - OCR 識別：3-5倍提升
  - 圖像修復：10-20倍提升

---

## 🔗 相關資源

- **ROCm 7 Whl 包下載**：`https://d2awnip2yjpvqn.cloudfront.net/v2/gfx120X-all/`
- **AMD TheRock 官方文檔**：`https://github.com/ROCm/TheRock/blob/main/RELEASES.md`
- **Manga Translator UI 官方倉庫**：`https://github.com/hgmzhn/manga-translator-ui`
- **ROCm 文檔**：`https://rocm.docs.amd.com/`

---

## 🎓 下一步學習

1. **學習 Manga Translator UI 基礎使用**
   - 查看 `doc/USAGE.md` 詳細教程
2. **配置翻譯器**
   - 設置在線翻譯器 API（Google、OpenAI、DeepL 等）
   - 或使用離線翻譯器（Sugoi、NLLB 等）
3. **探索高級功能**
   - 可視化編輯器
   - 批量處理
   - 自定義字體和樣式
4. **加入社區交流**
   - 查看 GitHub Issues 和 Discussions

---

## ✅ 部署完成檢查清單

- [ ] Python 3.13 已安裝並添加到 PATH
- [ ] Anaconda/Miniconda 已安裝
- [ ] Visual Studio 2022 C++ 工具已安裝
- [ ] Git 已安裝
- [ ] Manga Translator UI 倉庫已克隆
- [ ] Conda 環境 `manga` 已創建
- [ ] PyTorch + ROCm 7 已安裝（gfx120X-all）
- [ ] `python -c "import torch; print(torch.cuda.is_available())"` 輸出 True
- [ ] Manga Translator UI 依賴已安裝（requirements_rocm.txt）
- [ ] 首次啟動成功（start-rocm.bat）
- [ ] 啟動腳本路徑已正確配置
- [ ] GPU 加速已在界面中啟用

---

**祝您使用愉快！如有問題歡迎反饋。** 🎉





